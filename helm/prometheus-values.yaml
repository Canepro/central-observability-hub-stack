# Prometheus Standalone Helm Chart Values
# Chart: prometheus-community/prometheus
# Version: 27.47.0+

# --- ðŸš¨ CRITICAL: TOP LEVEL CONFIGURATION ðŸš¨ ---
# serverFiles must be at the top level, NOT nested under 'server:'
# NOTE: Do NOT include 'global:' or 'alerting:' in serverFiles.prometheus.yml
# as the chart generates those from server.global and alertmanager sections.
# Disable ALL default scrape configs - we define custom ones in serverFiles
scrapeConfigs:
  prometheus:
    enabled: false
  kubernetes-apiservers:
    enabled: false
  kubernetes-nodes:
    enabled: false
  kubernetes-nodes-cadvisor:
    enabled: false
  kubernetes-service-endpoints:
    enabled: false
  kubernetes-service-endpoints-slow:
    enabled: false
  kubernetes-services:
    enabled: false
  kubernetes-pods:
    enabled: false
  kubernetes-pods-slow:
    enabled: false
  prometheus-pushgateway:
    enabled: false

# The prometheus chart (28.x) ClusterRole no longer includes `nodes/proxy`.
# Our custom scrape job `kubernetes-nodes-cadvisor` uses the apiserver proxy path
# `/api/v1/nodes/<node>/proxy/metrics/cadvisor`, which requires this permission.
# Without it, targets go `DOWN` with `403 Forbidden` and container/cAdvisor metrics are missing.
extraManifests:
  - |
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole
    metadata:
      name: prometheus-server-node-proxy
      labels:
        app.kubernetes.io/name: prometheus
        app.kubernetes.io/component: server
    rules:
      - apiGroups: [""]
        resources: ["nodes/proxy"]
        verbs: ["get"]
  - |
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRoleBinding
    metadata:
      name: prometheus-server-node-proxy
      labels:
        app.kubernetes.io/name: prometheus
        app.kubernetes.io/component: server
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: ClusterRole
      name: prometheus-server-node-proxy
    subjects:
      - kind: ServiceAccount
        name: prometheus-server
        namespace: monitoring

serverFiles:
  # Custom Prometheus config with cluster label relabeling for all scrape jobs.
  # This ensures hub metrics are queryable with cluster="oke-hub" in dashboards.
  prometheus.yml:
    rule_files:
      - /etc/config/recording_rules.yml
      - /etc/config/alerting_rules.yml
      - /etc/config/rules
      - /etc/config/alerts

    scrape_configs:
      - job_name: kubernetes-apiservers
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        kubernetes_sd_configs:
          - role: endpoints
        relabel_configs:
          - action: keep
            regex: default;kubernetes;https
            source_labels:
              - __meta_kubernetes_namespace
              - __meta_kubernetes_service_name
              - __meta_kubernetes_endpoint_port_name
          - target_label: cluster
            replacement: oke-hub
          - target_label: origin_prometheus
            replacement: oke-hub
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt

      - job_name: kubernetes-nodes
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - replacement: kubernetes.default.svc:443
            target_label: __address__
          - regex: (.+)
            replacement: /api/v1/nodes/$1/proxy/metrics
            source_labels:
              - __meta_kubernetes_node_name
            target_label: __metrics_path__
          # Compatibility label: many k8s dashboards expect `node=...` on kubelet/cAdvisor series.
          - source_labels:
              - __meta_kubernetes_node_name
            target_label: node
          - source_labels:
              - __meta_kubernetes_node_name
            target_label: service
          - target_label: cluster
            replacement: oke-hub
          - target_label: origin_prometheus
            replacement: oke-hub
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt

      - job_name: kubernetes-nodes-cadvisor
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        kubernetes_sd_configs:
          - role: node
        relabel_configs:
          - action: labelmap
            regex: __meta_kubernetes_node_label_(.+)
          - replacement: kubernetes.default.svc:443
            target_label: __address__
          - regex: (.+)
            replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor
            source_labels:
              - __meta_kubernetes_node_name
            target_label: __metrics_path__
          # Compatibility label: many k8s dashboards expect `node=...` on kubelet/cAdvisor series.
          - source_labels:
              - __meta_kubernetes_node_name
            target_label: node
          - source_labels:
              - __meta_kubernetes_node_name
            target_label: service
          - target_label: cluster
            replacement: oke-hub
          - target_label: origin_prometheus
            replacement: oke-hub
        scheme: https
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt

      # Node Exporter (Prometheus chart)
      - job_name: node-exporter
        kubernetes_sd_configs:
          - role: endpoints
        relabel_configs:
          - action: keep
            source_labels:
              - __meta_kubernetes_namespace
              - __meta_kubernetes_service_name
            regex: monitoring;prometheus-prometheus-node-exporter
          - source_labels:
              - __meta_kubernetes_endpoint_node_name
            target_label: service
          - target_label: cluster
            replacement: oke-hub
          - target_label: origin_prometheus
            replacement: oke-hub

      # Kube State Metrics (Prometheus chart)
      - job_name: kube-state-metrics
        kubernetes_sd_configs:
          - role: endpoints
        relabel_configs:
          - action: keep
            source_labels:
              - __meta_kubernetes_namespace
              - __meta_kubernetes_service_name
            regex: monitoring;prometheus-kube-state-metrics
          - target_label: cluster
            replacement: oke-hub
          - target_label: origin_prometheus
            replacement: oke-hub

      # Argo CD metrics (Helm chart installs several *-metrics services).
      # Scrape these explicitly (they are not guaranteed to be annotated).
      - job_name: argocd-metrics
        kubernetes_sd_configs:
          - role: endpoints
            namespaces:
              names: [argocd]
        relabel_configs:
          - action: keep
            source_labels: [__meta_kubernetes_service_name]
            regex: argocd-.*-metrics
          - action: keep
            source_labels: [__meta_kubernetes_endpoint_port_name]
            regex: http-metrics
          - action: replace
            source_labels: [__meta_kubernetes_service_name]
            target_label: job
            replacement: $1
          - action: replace
            source_labels: [__meta_kubernetes_service_name]
            target_label: service
            replacement: $1
          - action: replace
            source_labels: [__meta_kubernetes_namespace]
            target_label: namespace
          - target_label: cluster
            replacement: oke-hub
          - target_label: origin_prometheus
            replacement: oke-hub

      - job_name: kubernetes-service-endpoints
        honor_labels: true
        kubernetes_sd_configs:
          - role: endpoints
        relabel_configs:
          # Normalize job labels for common gnet dashboards
          - action: replace
            source_labels:
              - __meta_kubernetes_service_name
            regex: prometheus-prometheus-node-exporter
            target_label: job
            replacement: node-exporter
          - action: replace
            source_labels:
              - __meta_kubernetes_service_name
            regex: prometheus-kube-state-metrics
            target_label: job
            replacement: kube-state-metrics
          - action: replace
            source_labels:
              - __meta_kubernetes_service_name
            regex: prometheus-alertmanager
            target_label: job
            replacement: alertmanager
          # Expose Argo CD metrics with job=<service_name> so gnet dashboards and
          # alert rules can match `job="argocd-*-metrics"`.
          - action: replace
            source_labels:
              - __meta_kubernetes_service_name
            regex: (argocd-.*-metrics)
            target_label: job
            replacement: $1
          - action: keep
            regex: true
            source_labels:
              - __meta_kubernetes_service_annotation_prometheus_io_scrape
          - action: drop
            regex: true
            source_labels:
              - __meta_kubernetes_service_annotation_prometheus_io_scrape_slow
          - action: replace
            regex: (https?)
            source_labels:
              - __meta_kubernetes_service_annotation_prometheus_io_scheme
            target_label: __scheme__
          - action: replace
            regex: (.+)
            source_labels:
              - __meta_kubernetes_service_annotation_prometheus_io_path
            target_label: __metrics_path__
          - action: replace
            regex: (.+?)(?::\d+)?;(\d+)
            replacement: $1:$2
            source_labels:
              - __address__
              - __meta_kubernetes_service_annotation_prometheus_io_port
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_service_annotation_prometheus_io_param_(.+)
            replacement: __param_$1
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - action: replace
            source_labels:
              - __meta_kubernetes_namespace
            target_label: namespace
          - action: replace
            source_labels:
              - __meta_kubernetes_service_name
            target_label: service
          - action: replace
            source_labels:
              - __meta_kubernetes_pod_node_name
            target_label: node
          - target_label: cluster
            replacement: oke-hub

      - job_name: kubernetes-service-endpoints-slow
        honor_labels: true
        kubernetes_sd_configs:
          - role: endpoints
        scrape_interval: 5m
        scrape_timeout: 30s
        relabel_configs:
          - action: keep
            regex: true
            source_labels:
              - __meta_kubernetes_service_annotation_prometheus_io_scrape_slow
          - action: replace
            regex: (https?)
            source_labels:
              - __meta_kubernetes_service_annotation_prometheus_io_scheme
            target_label: __scheme__
          - action: replace
            regex: (.+)
            source_labels:
              - __meta_kubernetes_service_annotation_prometheus_io_path
            target_label: __metrics_path__
          - action: replace
            regex: (.+?)(?::\d+)?;(\d+)
            replacement: $1:$2
            source_labels:
              - __address__
              - __meta_kubernetes_service_annotation_prometheus_io_port
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_service_annotation_prometheus_io_param_(.+)
            replacement: __param_$1
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - action: replace
            source_labels:
              - __meta_kubernetes_namespace
            target_label: namespace
          - action: replace
            source_labels:
              - __meta_kubernetes_service_name
            target_label: service
          - action: replace
            source_labels:
              - __meta_kubernetes_pod_node_name
            target_label: node
          - target_label: cluster
            replacement: oke-hub

      - job_name: prometheus-pushgateway
        honor_labels: true
        kubernetes_sd_configs:
          - role: service
        relabel_configs:
          - action: keep
            regex: pushgateway
            source_labels:
              - __meta_kubernetes_service_annotation_prometheus_io_probe
          - target_label: cluster
            replacement: oke-hub

      - job_name: kubernetes-services
        honor_labels: true
        kubernetes_sd_configs:
          - role: service
        metrics_path: /probe
        params:
          module:
            - http_2xx
        relabel_configs:
          - action: keep
            regex: true
            source_labels:
              - __meta_kubernetes_service_annotation_prometheus_io_probe
          - source_labels:
              - __address__
            target_label: __param_target
          - replacement: blackbox
            target_label: __address__
          - source_labels:
              - __param_target
            target_label: instance
          - action: labelmap
            regex: __meta_kubernetes_service_label_(.+)
          - source_labels:
              - __meta_kubernetes_namespace
            target_label: namespace
          - source_labels:
              - __meta_kubernetes_service_name
            target_label: service
          - target_label: cluster
            replacement: oke-hub

      - job_name: kubernetes-pods
        honor_labels: true
        kubernetes_sd_configs:
          - role: pod
        relabel_configs:
          - action: keep
            regex: true
            source_labels:
              - __meta_kubernetes_pod_annotation_prometheus_io_scrape
          - action: drop
            regex: true
            source_labels:
              - __meta_kubernetes_pod_annotation_prometheus_io_scrape_slow
          - action: replace
            regex: (https?)
            source_labels:
              - __meta_kubernetes_pod_annotation_prometheus_io_scheme
            target_label: __scheme__
          - action: replace
            regex: (.+)
            source_labels:
              - __meta_kubernetes_pod_annotation_prometheus_io_path
            target_label: __metrics_path__
          - action: replace
            regex: (\d+);(([A-Fa-f0-9]{1,4}::?){1,7}[A-Fa-f0-9]{1,4})
            replacement: '[$2]:$1'
            source_labels:
              - __meta_kubernetes_pod_annotation_prometheus_io_port
              - __meta_kubernetes_pod_ip
            target_label: __address__
          - action: replace
            regex: (\d+);((([0-9]+?)(\.|$)){4})
            replacement: $2:$1
            source_labels:
              - __meta_kubernetes_pod_annotation_prometheus_io_port
              - __meta_kubernetes_pod_ip
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)
            replacement: __param_$1
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - action: replace
            source_labels:
              - __meta_kubernetes_namespace
            target_label: namespace
          - action: replace
            source_labels:
              - __meta_kubernetes_pod_name
            target_label: pod
          - action: drop
            regex: Pending|Succeeded|Failed|Completed
            source_labels:
              - __meta_kubernetes_pod_phase
          - action: replace
            source_labels:
              - __meta_kubernetes_pod_node_name
            target_label: node
          - target_label: cluster
            replacement: oke-hub

      - job_name: kubernetes-pods-slow
        honor_labels: true
        kubernetes_sd_configs:
          - role: pod
        scrape_interval: 5m
        scrape_timeout: 30s
        relabel_configs:
          - action: keep
            regex: true
            source_labels:
              - __meta_kubernetes_pod_annotation_prometheus_io_scrape_slow
          - action: replace
            regex: (https?)
            source_labels:
              - __meta_kubernetes_pod_annotation_prometheus_io_scheme
            target_label: __scheme__
          - action: replace
            regex: (.+)
            source_labels:
              - __meta_kubernetes_pod_annotation_prometheus_io_path
            target_label: __metrics_path__
          - action: replace
            regex: (\d+);(([A-Fa-f0-9]{1,4}::?){1,7}[A-Fa-f0-9]{1,4})
            replacement: '[$2]:$1'
            source_labels:
              - __meta_kubernetes_pod_annotation_prometheus_io_port
              - __meta_kubernetes_pod_ip
            target_label: __address__
          - action: replace
            regex: (\d+);((([0-9]+?)(\.|$)){4})
            replacement: $2:$1
            source_labels:
              - __meta_kubernetes_pod_annotation_prometheus_io_port
              - __meta_kubernetes_pod_ip
            target_label: __address__
          - action: labelmap
            regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)
            replacement: __param_$1
          - action: labelmap
            regex: __meta_kubernetes_pod_label_(.+)
          - action: replace
            source_labels:
              - __meta_kubernetes_namespace
            target_label: namespace
          - action: replace
            source_labels:
              - __meta_kubernetes_pod_name
            target_label: pod
          - action: drop
            regex: Pending|Succeeded|Failed|Completed
            source_labels:
              - __meta_kubernetes_pod_phase
          - action: replace
            source_labels:
              - __meta_kubernetes_pod_node_name
            target_label: node
          - target_label: cluster
            replacement: oke-hub

      # Custom scrape: kubelet PVC stats for OKE dashboarding
      - job_name: kubelet-volume-stats
        scheme: https
        kubernetes_sd_configs:
          - role: node
        tls_config:
          ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
        bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
        relabel_configs:
          - target_label: __address__
            replacement: kubernetes.default.svc:443
          - source_labels: [__meta_kubernetes_node_name]
            target_label: __metrics_path__
            replacement: /api/v1/nodes/${1}/proxy/metrics
          - target_label: cluster
            replacement: oke-hub
        metric_relabel_configs:
          - source_labels: [__name__]
            action: keep
            regex: kubelet_volume_stats_(used_bytes|capacity_bytes|available_bytes|inodes|inodes_free)

  alerting_rules.yml:
    groups:
      - name: WorldTreeAlerts
        rules:
          # 1. Spoke Heartbeat: Kind Cluster (Training)
          - alert: KindSpokeOffline
            expr: up{job="kind-kind-cluster"} == 0
            for: 2m
            labels:
              severity: critical
            annotations:
              summary: "Kind Spoke Offline"
              description: "The L4 proxy on port 6443 or the Lab Server is unreachable."

          # 2. Hub Infrastructure: OKE Storage
          - alert: OKEStorageWarning
            expr: (kubelet_volume_stats_available_bytes{cluster="oke-hub"} / kubelet_volume_stats_capacity_bytes{cluster="oke-hub"}) * 100 < 15
            for: 5m
            labels:
              severity: warning
            annotations:
              summary: "Low Disk Space on OKE"
              description: "OKE Storage on {{ $labels.node }} is below 15% free space."

          # 3. GitOps Heartbeat: Argo CD Controller
          - alert: ArgoCDControllerDown
            # Prefer kube-state-metrics over scrape-target job labels (more stable across scrape config changes)
            expr: kube_statefulset_status_replicas_ready{namespace="argocd",statefulset="argocd-application-controller",cluster="oke-hub"} < 1
            for: 2m
            labels:
              severity: critical
            annotations:
              summary: "ArgoCD Monitoring Down"
              description: "ArgoCD application-controller is not Ready (StatefulSet argocd/argocd-application-controller)."

          # 4. GitOps Health: Application Status
          - alert: ArgoCDApplicationDegraded
            expr: argocd_app_info{health_status="Degraded",cluster="oke-hub"} == 1
            for: 5m
            labels:
              severity: critical
            annotations:
              summary: "GitOps Application Degraded"
              description: "Application {{ $labels.name }} in project {{ $labels.project }} is in a failed state."

      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # Tier 1: OKE Hub Cluster (oke-hub)
      # Metrics are scraped locally; filter with cluster="oke-hub"
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: HubNodeAlerts
        rules:
          - alert: HubNodeHighCPU
            expr: |
              (
                1 - avg by (service, cluster) (rate(node_cpu_seconds_total{mode="idle", cluster="oke-hub"}[5m]))
              ) * 100 > 85
            for: 10m
            labels:
              severity: warning
              cluster: oke-hub
            annotations:
              summary: "OKE hub node CPU > 85% for 10m"
              description: "Node {{ $labels.service }} CPU usage is {{ $value | printf \"%.1f\" }}%."

          - alert: HubNodeHighMemory
            expr: |
              (
                1 - (node_memory_MemAvailable_bytes{cluster="oke-hub"} / node_memory_MemTotal_bytes{cluster="oke-hub"})
              ) * 100 > 85
            for: 10m
            labels:
              severity: warning
              cluster: oke-hub
            annotations:
              summary: "OKE hub node memory > 85% for 10m"
              description: "Node {{ $labels.service }} memory usage is {{ $value | printf \"%.1f\" }}%."

          - alert: HubNodeDiskPressure
            expr: |
              (
                1 - (node_filesystem_avail_bytes{cluster="oke-hub", mountpoint="/", fstype!="tmpfs"} / node_filesystem_size_bytes{cluster="oke-hub", mountpoint="/", fstype!="tmpfs"})
              ) * 100 > 85
            for: 10m
            labels:
              severity: warning
              cluster: oke-hub
            annotations:
              summary: "OKE hub node disk > 85% full"
              description: "Node {{ $labels.service }} root disk usage is {{ $value | printf \"%.1f\" }}%."

          - alert: HubNodeNotReady
            expr: kube_node_status_condition{condition="Ready", status="true", cluster="oke-hub"} == 0
            for: 5m
            labels:
              severity: critical
              cluster: oke-hub
            annotations:
              summary: "OKE hub node not ready"
              description: "Node {{ $labels.node }} has been NotReady for 5 minutes."

      - name: HubPodAlerts
        rules:
          - alert: HubPodCrashLooping
            expr: |
              rate(kube_pod_container_status_restarts_total{cluster="oke-hub", namespace=~"monitoring|argocd"}[15m]) * 60 * 15 > 3
            for: 10m
            labels:
              severity: warning
              cluster: oke-hub
            annotations:
              summary: "Pod crash-looping on OKE hub"
              description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) restarted {{ $value | printf \"%.0f\" }} times in 15m."

          - alert: HubContainerOOMKilled
            expr: |
              kube_pod_container_status_last_terminated_reason{reason="OOMKilled", cluster="oke-hub", namespace=~"monitoring|argocd"} == 1
            for: 0m
            labels:
              severity: warning
              cluster: oke-hub
            annotations:
              summary: "Container OOMKilled on OKE hub"
              description: "{{ $labels.namespace }}/{{ $labels.pod }} container {{ $labels.container }} was OOMKilled."

          - alert: HubPodStuckPending
            expr: |
              kube_pod_status_phase{phase="Pending", cluster="oke-hub", namespace=~"monitoring|argocd"} == 1
            for: 15m
            labels:
              severity: warning
              cluster: oke-hub
            annotations:
              summary: "Pod stuck Pending on OKE hub"
              description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} has been Pending for > 15m."

      - name: HubWorkloadAlerts
        rules:
          - alert: HubDeploymentReplicasMismatch
            expr: |
              kube_deployment_status_replicas_available{cluster="oke-hub", namespace=~"monitoring|argocd"}
                != kube_deployment_spec_replicas{cluster="oke-hub", namespace=~"monitoring|argocd"}
            for: 15m
            labels:
              severity: warning
              cluster: oke-hub
            annotations:
              summary: "OKE hub Deployment replicas mismatch"
              description: "Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has {{ $value }} available vs desired."

          - alert: HubStatefulSetReplicasMismatch
            expr: |
              kube_statefulset_status_replicas_ready{cluster="oke-hub", namespace=~"monitoring|argocd"}
                != kube_statefulset_replicas{cluster="oke-hub", namespace=~"monitoring|argocd"}
            for: 15m
            labels:
              severity: warning
              cluster: oke-hub
            annotations:
              summary: "OKE hub StatefulSet replicas mismatch"
              description: "StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} has {{ $value }} ready vs desired."

          - alert: HubDaemonSetMissScheduled
            expr: |
              kube_daemonset_status_desired_number_scheduled{cluster="oke-hub", namespace=~"monitoring|argocd|ingress-nginx|kube-system"}
                - kube_daemonset_status_current_number_scheduled{cluster="oke-hub", namespace=~"monitoring|argocd|ingress-nginx|kube-system"} > 0
            for: 10m
            labels:
              severity: warning
              cluster: oke-hub
            annotations:
              summary: "OKE hub DaemonSet not fully scheduled"
              description: "DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} is missing pods on some nodes."

      - name: HubMonitoringStackHealth
        rules:
          - alert: PrometheusServerUnavailable
            expr: kube_deployment_status_replicas_available{deployment="prometheus-server", namespace="monitoring", cluster="oke-hub"} < 1
            for: 5m
            labels:
              severity: critical
              cluster: oke-hub
            annotations:
              summary: "Prometheus server unavailable"
              description: "Deployment monitoring/prometheus-server has 0 available replicas."

          - alert: GrafanaUnavailable
            expr: kube_deployment_status_replicas_available{deployment="grafana", namespace="monitoring", cluster="oke-hub"} < 1
            for: 5m
            labels:
              severity: critical
              cluster: oke-hub
            annotations:
              summary: "Grafana unavailable"
              description: "Deployment monitoring/grafana has 0 available replicas."

          - alert: LokiUnavailable
            expr: kube_statefulset_status_replicas_ready{statefulset="loki", namespace="monitoring", cluster="oke-hub"} < 1
            for: 10m
            labels:
              severity: critical
              cluster: oke-hub
            annotations:
              summary: "Loki unavailable"
              description: "StatefulSet monitoring/loki has 0 ready replicas."

          - alert: TempoUnavailable
            expr: kube_statefulset_status_replicas_ready{statefulset="tempo", namespace="monitoring", cluster="oke-hub"} < 1
            for: 10m
            labels:
              severity: critical
              cluster: oke-hub
            annotations:
              summary: "Tempo unavailable"
              description: "StatefulSet monitoring/tempo has 0 ready replicas."

          - alert: AlertmanagerUnavailable
            expr: kube_statefulset_status_replicas_ready{statefulset="prometheus-alertmanager", namespace="monitoring", cluster="oke-hub"} < 1
            for: 10m
            labels:
              severity: critical
              cluster: oke-hub
            annotations:
              summary: "Alertmanager unavailable"
              description: "StatefulSet monitoring/prometheus-alertmanager has 0 ready replicas."

      - name: HubPrometheusScrapeHealth
        rules:
          - alert: HubCadvisorScrapeDown
            expr: up{job="kubernetes-nodes-cadvisor", cluster="oke-hub"} == 0
            for: 5m
            labels:
              severity: critical
              cluster: oke-hub
            annotations:
              summary: "cAdvisor scrape down"
              description: "Prometheus cannot scrape cAdvisor for node {{ $labels.service }} (job kubernetes-nodes-cadvisor)."

          - alert: HubKubeletVolumeStatsScrapeDown
            expr: up{job="kubelet-volume-stats", cluster="oke-hub"} == 0
            for: 5m
            labels:
              severity: warning
              cluster: oke-hub
            annotations:
              summary: "kubelet volume stats scrape down"
              description: "Prometheus cannot scrape kubelet volume stats for node {{ $labels.instance }} (job kubelet-volume-stats)."

      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      # Tier 4: AKS Spoke Cluster (aks-canepro)
      # Metrics arrive via remote-write; filter with cluster="aks-canepro"
      # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: AKSSpokeNodeAlerts
        rules:
          # Node CPU sustained high
          - alert: AKSNodeHighCPU
            expr: |
              (
                1 - avg by (instance, cluster) (rate(node_cpu_seconds_total{mode="idle", cluster="aks-canepro"}[5m]))
              ) * 100 > 85
            for: 10m
            labels:
              severity: warning
              cluster: aks-canepro
            annotations:
              summary: "AKS node CPU > 85% for 10m"
              description: "Node {{ $labels.instance }} CPU usage is {{ $value | printf \"%.1f\" }}%."

          # Node memory pressure
          - alert: AKSNodeHighMemory
            expr: |
              (
                1 - (node_memory_MemAvailable_bytes{cluster="aks-canepro"} / node_memory_MemTotal_bytes{cluster="aks-canepro"})
              ) * 100 > 85
            for: 10m
            labels:
              severity: warning
              cluster: aks-canepro
            annotations:
              summary: "AKS node memory > 85% for 10m"
              description: "Node {{ $labels.instance }} memory usage is {{ $value | printf \"%.1f\" }}%."

          # Node disk pressure (root filesystem)
          - alert: AKSNodeDiskPressure
            expr: |
              (
                1 - (node_filesystem_avail_bytes{cluster="aks-canepro", mountpoint="/", fstype!="tmpfs"} / node_filesystem_size_bytes{cluster="aks-canepro", mountpoint="/", fstype!="tmpfs"})
              ) * 100 > 85
            for: 10m
            labels:
              severity: warning
              cluster: aks-canepro
            annotations:
              summary: "AKS node disk > 85% full"
              description: "Node {{ $labels.instance }} root disk usage is {{ $value | printf \"%.1f\" }}%."

          # Node not ready
          - alert: AKSNodeNotReady
            expr: kube_node_status_condition{condition="Ready", status="true", cluster="aks-canepro"} == 0
            for: 5m
            labels:
              severity: critical
              cluster: aks-canepro
            annotations:
              summary: "AKS node not ready"
              description: "Node {{ $labels.node }} has been NotReady for 5 minutes."

      - name: AKSSpokePodAlerts
        rules:
          # Pod CrashLoopBackOff
          - alert: AKSPodCrashLooping
            expr: |
              rate(kube_pod_container_status_restarts_total{cluster="aks-canepro"}[15m]) * 60 * 15 > 3
            for: 10m
            labels:
              severity: warning
              cluster: aks-canepro
            annotations:
              summary: "Pod crash-looping on AKS"
              description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) restarted {{ $value | printf \"%.0f\" }} times in 15m."

          # Container OOMKilled
          - alert: AKSContainerOOMKilled
            expr: |
              kube_pod_container_status_last_terminated_reason{reason="OOMKilled", cluster="aks-canepro"} == 1
            for: 0m
            labels:
              severity: warning
              cluster: aks-canepro
            annotations:
              summary: "Container OOMKilled on AKS"
              description: "{{ $labels.namespace }}/{{ $labels.pod }} container {{ $labels.container }} was OOMKilled."

          # Pods stuck in Pending
          - alert: AKSPodStuckPending
            expr: |
              kube_pod_status_phase{phase="Pending", cluster="aks-canepro"} == 1
            for: 15m
            labels:
              severity: warning
              cluster: aks-canepro
            annotations:
              summary: "Pod stuck Pending on AKS"
              description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} has been Pending for > 15m."

          # Many stale pods (Evicted/Failed/Unknown)
          - alert: AKSManyStalePods
            expr: |
              (
                count(kube_pod_status_phase{phase="Failed", cluster="aks-canepro"}) or vector(0)
              ) + (
                count(kube_pod_status_phase{phase="Unknown", cluster="aks-canepro"}) or vector(0)
              ) + (
                count(kube_pod_status_phase{phase="Succeeded", cluster="aks-canepro"}) or vector(0)
              ) > 15
            for: 30m
            labels:
              severity: warning
              cluster: aks-canepro
            annotations:
              summary: "More than 15 stale pods on AKS"
              description: "{{ $value }} pods in terminal states. Check aks-stale-pod-cleanup CronJob."

      - name: AKSSpokeWorkloadAlerts
        rules:
          # Deployment replicas mismatch
          - alert: AKSDeploymentReplicasMismatch
            expr: |
              kube_deployment_status_replicas_available{cluster="aks-canepro"}
                != kube_deployment_spec_replicas{cluster="aks-canepro"}
            for: 15m
            labels:
              severity: warning
              cluster: aks-canepro
            annotations:
              summary: "AKS Deployment replicas mismatch"
              description: "Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has {{ $value }} available vs desired."

          # StatefulSet replicas mismatch
          - alert: AKSStatefulSetReplicasMismatch
            expr: |
              kube_statefulset_status_replicas_ready{cluster="aks-canepro"}
                != kube_statefulset_replicas{cluster="aks-canepro"}
            for: 15m
            labels:
              severity: warning
              cluster: aks-canepro
            annotations:
              summary: "AKS StatefulSet replicas mismatch"
              description: "StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} has {{ $value }} ready vs desired."

          # DaemonSet not scheduled on all nodes
          - alert: AKSDaemonSetMissScheduled
            expr: |
              kube_daemonset_status_desired_number_scheduled{cluster="aks-canepro"}
                - kube_daemonset_status_current_number_scheduled{cluster="aks-canepro"} > 0
            for: 10m
            labels:
              severity: warning
              cluster: aks-canepro
            annotations:
              summary: "AKS DaemonSet not fully scheduled"
              description: "DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} is missing pods on some nodes."

      - name: AKSSpokeApplicationAlerts
        rules:
          # Rocket.Chat main app down
          - alert: AKSRocketChatDown
            expr: |
              kube_deployment_status_replicas_available{deployment="rocketchat-rocketchat", namespace="rocketchat", cluster="aks-canepro"} == 0
            for: 5m
            labels:
              severity: critical
              cluster: aks-canepro
            annotations:
              summary: "Rocket.Chat is down on AKS"
              description: "No available replicas for rocketchat-rocketchat deployment."

          # MongoDB down
          - alert: AKSMongoDBDown
            expr: |
              kube_statefulset_status_replicas_ready{statefulset="mongodb", namespace="rocketchat", cluster="aks-canepro"} == 0
            for: 5m
            labels:
              severity: critical
              cluster: aks-canepro
            annotations:
              summary: "MongoDB is down on AKS"
              description: "MongoDB StatefulSet has 0 ready replicas."

          # NATS down
          - alert: AKSNATSDown
            expr: |
              kube_statefulset_status_replicas_ready{statefulset="rocketchat-nats", namespace="rocketchat", cluster="aks-canepro"} == 0
            for: 5m
            labels:
              severity: critical
              cluster: aks-canepro
            annotations:
              summary: "NATS is down on AKS"
              description: "NATS StatefulSet has 0 ready replicas. Rocket.Chat microservices cannot communicate."

          # Jenkins controller down
          - alert: AKSJenkinsDown
            expr: |
              kube_statefulset_status_replicas_ready{statefulset="jenkins", namespace="jenkins", cluster="aks-canepro"} == 0
            for: 5m
            labels:
              severity: warning
              cluster: aks-canepro
            annotations:
              summary: "Jenkins is down on AKS"
              description: "Jenkins StatefulSet has 0 ready replicas."

      - name: AKSSpokeStorageAlerts
        rules:
          # PVC usage high
          - alert: AKSPVCUsageHigh
            expr: |
              (
                kubelet_volume_stats_used_bytes{cluster="aks-canepro"}
                / kubelet_volume_stats_capacity_bytes{cluster="aks-canepro"}
              ) * 100 > 85
            for: 10m
            labels:
              severity: warning
              cluster: aks-canepro
            annotations:
              summary: "AKS PVC usage > 85%"
              description: "PVC {{ $labels.persistentvolumeclaim }} in {{ $labels.namespace }} is {{ $value | printf \"%.1f\" }}% full."

          # PVC usage critical
          - alert: AKSPVCUsageCritical
            expr: |
              (
                kubelet_volume_stats_used_bytes{cluster="aks-canepro"}
                / kubelet_volume_stats_capacity_bytes{cluster="aks-canepro"}
              ) * 100 > 95
            for: 5m
            labels:
              severity: critical
              cluster: aks-canepro
            annotations:
              summary: "AKS PVC usage > 95%"
              description: "PVC {{ $labels.persistentvolumeclaim }} in {{ $labels.namespace }} is {{ $value | printf \"%.1f\" }}% full. Immediate action needed."

      - name: AKSSpokeObservabilityAlerts
        rules:
          # Prometheus remote-write failures
          - alert: AKSPrometheusRemoteWriteFailing
            expr: |
              rate(prometheus_remote_storage_failed_samples_total{cluster="aks-canepro"}[5m]) > 0
            for: 10m
            labels:
              severity: warning
              cluster: aks-canepro
            annotations:
              summary: "AKS Prometheus remote-write failing"
              description: "Prometheus Agent on AKS is failing to send samples to the hub. Metrics may be delayed or lost."

          # Promtail not running on all nodes
          - alert: AKSPromtailDown
            expr: |
              kube_daemonset_status_number_ready{daemonset="promtail", namespace="monitoring", cluster="aks-canepro"}
                < kube_daemonset_status_desired_number_scheduled{daemonset="promtail", namespace="monitoring", cluster="aks-canepro"}
            for: 10m
            labels:
              severity: warning
              cluster: aks-canepro
            annotations:
              summary: "Promtail not running on all AKS nodes"
              description: "{{ $value }} Promtail pods are missing. Log collection is incomplete."

          # Kube-state-metrics down
          - alert: AKSKubeStateMetricsDown
            expr: |
              kube_deployment_status_replicas_available{deployment="kube-state-metrics", namespace="monitoring", cluster="aks-canepro"} == 0
            for: 5m
            labels:
              severity: critical
              cluster: aks-canepro
            annotations:
              summary: "kube-state-metrics is down on AKS"
              description: "Kubernetes object metrics are unavailable. Most cluster alerts will stop firing."

      - name: AKSSpokeNetworkAlerts
        rules:
          # CoreDNS down
          - alert: AKSCoreDNSDown
            expr: |
              kube_deployment_status_replicas_available{deployment="coredns", namespace="kube-system", cluster="aks-canepro"} == 0
            for: 2m
            labels:
              severity: critical
              cluster: aks-canepro
            annotations:
              summary: "CoreDNS is down on AKS"
              description: "All CoreDNS replicas are unavailable. DNS resolution will fail cluster-wide."

configmapReload:
  prometheus:
    enabled: true

server:
  retention: "15d"

  extraFlags:
    - web.enable-remote-write-receiver
    - web.enable-lifecycle

  # Pod annotations to force restart when config changes
  podAnnotations:
    config-reload-timestamp: "2026-01-18T20:45:00Z"

  persistentVolume:
    enabled: true
    size: 50Gi
    storageClass: oci-bv
    accessModes:
      - ReadWriteOnce

  resources:
    requests:
      cpu: 500m
      memory: 1Gi
    limits:
      cpu: 2
      memory: 2Gi

  service:
    servicePort: 80
    type: ClusterIP

  # Global config (chart generates this into prometheus.yml)
  global:
    scrape_interval: 30s
    evaluation_interval: 30s
    external_labels:
      cluster: oke-hub
      environment: production
      workspace: hub
      domain: observability.canepro.me
      # Some gnet dashboards (for example StarsL 13105) filter on `origin_prometheus`.
      origin_prometheus: oke-hub

# Alertmanager configuration
alertmanager:
  enabled: true
  # Alertmanager config uses ${SMTP_*} placeholders. The upstream Alertmanager
  # binary only expands env vars when `--config.expand-env` is enabled.
  extraArgs:
    config.expand-env: "true"
  service:
    annotations:
      prometheus.io/scrape: "true"
      prometheus.io/port: "9093"
      prometheus.io/path: /metrics
  persistence:
    enabled: false
  resources:
    requests:
      cpu: 50m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 512Mi

  # NOTE: This chart uses `extraEnv` (not `extraEnvVars`).
  extraEnv:
    - name: SMTP_PASSWORD
      valueFrom:
        secretKeyRef:
          name: grafana-smtp-credentials
          key: password
    - name: SMTP_USER
      valueFrom:
        secretKeyRef:
          name: grafana-smtp-credentials
          key: user
    - name: SMTP_FROM
      valueFrom:
        secretKeyRef:
          name: grafana-smtp-credentials
          key: from_address
    - name: SMTP_TO
      valueFrom:
        secretKeyRef:
          name: grafana-smtp-credentials
          key: to_address

  config:
    global:
      resolve_timeout: 5m
      smtp_from: '${SMTP_FROM}'
      smtp_smarthost: 'smtp.gmail.com:587'
      smtp_auth_username: '${SMTP_USER}'
      smtp_auth_password: '${SMTP_PASSWORD}'
      smtp_require_tls: true

    # NOTE: If a time zone is not specified, times are interpreted as UTC.
    # Update `location` below if your AKS auto-start/stop schedule uses a different zone.
    time_intervals:
      - name: 'aks-canepro-down-hours'
        time_intervals:
          # AKS is expected to be OFF during these times.
          - weekdays: ['monday:friday']
            times:
              - start_time: '00:00'
                end_time: '16:00'
              - start_time: '23:00'
                end_time: '24:00'
            location: 'UTC'
          - weekdays: ['saturday', 'sunday']
            times:
              - start_time: '00:00'
                end_time: '24:00'
            location: 'UTC'

    route:
      group_by: ['alertname', 'cluster', 'severity']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 12h
      receiver: 'gmail-notifications'
      routes:
        # Avoid false positives during the scheduled AKS shutdown window.
        - receiver: 'gmail-notifications'
          matchers:
            - 'cluster="aks-canepro"'
          mute_time_intervals:
            - 'aks-canepro-down-hours'

    receivers:
      - name: 'gmail-notifications'
        email_configs:
          - to: '${SMTP_TO}'
            send_resolved: true

# Node Exporter for Infrastructure Metrics
nodeExporter:
  enabled: true
  resources:
    requests:
      cpu: 50m
      memory: 64Mi
    limits:
      cpu: 200m
      memory: 128Mi

# Kube State Metrics for Cluster Objects
kubeStateMetrics:
  enabled: true
  resources:
    requests:
      cpu: 50m
      memory: 128Mi
    limits:
      cpu: 200m
      memory: 256Mi

# Pushgateway for ephemeral/batch jobs
pushgateway:
  enabled: true
  resources:
    requests:
      cpu: 50m
      memory: 64Mi
    limits:
      cpu: 100m
      memory: 128Mi
